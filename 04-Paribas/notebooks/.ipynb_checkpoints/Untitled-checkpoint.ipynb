{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "#import load_data\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(attempt, actual, epsilon=1.0e-15):\n",
    "    \"\"\"Logloss, i.e. the score of the bioresponse competition.\n",
    "    \"\"\"\n",
    "    attempt = np.clip(attempt, epsilon, 1.0-epsilon)\n",
    "    return - np.mean(actual * np.log(attempt) + (1.0 - actual) * np.log(1.0 - attempt))\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "def PrepareData(train, test):\n",
    "    trainids = train.ID.values\n",
    "    testids = test.ID.values\n",
    "    targets = train['target'].values\n",
    "    features = train.columns[2:]\n",
    "    tokeep = ['v4', 'v6', 'v9', 'v10', 'v12', 'v14', 'v16',\n",
    "              'v18', 'v19', 'v21', 'v34', 'v36', 'v38', 'v39',\n",
    "              'v40', 'v45', 'v50', 'v53', 'v57', 'v58',\n",
    "              'v62', 'v68', 'v69', 'v72', 'v80', 'v81',\n",
    "              'v82', 'v85', 'v88', 'v90',\n",
    "              'v93', 'v98', 'v99', 'v100', 'v114', 'v115',\n",
    "              'v119', 'v120', 'v123', 'v124', 'v127', 'v129', 'v22',\n",
    "              'v24', 'v30', 'v31', 'v47', 'v52', 'v56', 'v66',\n",
    "              'v71', 'v75', 'v79', 'v112', 'v113', 'v125']\n",
    "\n",
    "    features = train.columns[2:]\n",
    "    todrop = list(set(features).difference(set(tokeep)))\n",
    "    train.drop(todrop, inplace=True, axis=1)\n",
    "    test.drop(todrop, inplace=True, axis=1)\n",
    "    #print(train.columns)\n",
    "    features = train.columns[2:]\n",
    "    for col in features:\n",
    "        #print(col)\n",
    "        if((train[col].dtype == 'object')):\n",
    "            train.loc[~train[col].isin(test[col]), col] = 'Orphans'\n",
    "            test.loc[~test[col].isin(train[col]), col] = 'Orphans'\n",
    "            train[col].fillna('Missing', inplace=True)\n",
    "            test[col].fillna('Missing', inplace=True)\n",
    "            train[col], tmp_indexer = pd.factorize(train[col])\n",
    "            test[col] = tmp_indexer.get_indexer(test[col])\n",
    "            traincounts = train[col].value_counts().reset_index()\n",
    "            traincounts.rename(columns={'index': col,\n",
    "                                        col: col+'_count'}, inplace=True)\n",
    "            traincounts = traincounts[traincounts[col+'_count'] >= 50]\n",
    "            # train = train.merge(traincounts, how='left', on=col)\n",
    "            # test = test.merge(traincounts, how='left', on=col)\n",
    "            g = train[[col, 'target']].copy().groupby(col).mean().reset_index()\n",
    "            g = g[g[col].isin(traincounts[col])]\n",
    "            g.rename(columns={'target': col+'_avg'}, inplace=True)\n",
    "            train = train.merge(g, how='left', on=col)\n",
    "            test = test.merge(g, how='left', on=col)\n",
    "            h = train[[col, 'target']].copy().groupby(col).std().reset_index()\n",
    "            h = h[h[col].isin(traincounts[col])]\n",
    "            h.rename(columns={'target': col+'_std'}, inplace=True)\n",
    "            train = train.merge(h, how='left', on=col)\n",
    "            test = test.merge(h, how='left', on=col)\n",
    "            train.drop(col, inplace=True, axis=1)\n",
    "            test.drop(col, inplace=True, axis=1)\n",
    "\n",
    "    features = train.columns[2:]\n",
    "    train.fillna(-1, inplace=True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "    train[features] = train[features].astype(float)\n",
    "    test[features] = test[features].astype(float)\n",
    "    gptrain = pd.DataFrame()\n",
    "    gptest = pd.DataFrame()\n",
    "    gptrain.insert(0, 'ID', trainids)\n",
    "    gptest.insert(0, 'ID', testids)\n",
    "    gptrain = pd.merge(gptrain, train[list(['ID'])+list(features)], on='ID')\n",
    "    gptest = pd.merge(gptest, test[list(['ID'])+list(features)], on='ID')\n",
    "    gptrain['TARGET'] = targets\n",
    "\n",
    "    del train\n",
    "    del test\n",
    "    gc.collect()\n",
    "    return gptrain, gptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'v4', u'v6', u'v9', u'v10', u'v12', u'v14', u'v16', u'v18', u'v19',\n",
      "       u'v21', u'v34', u'v36', u'v38', u'v39', u'v40', u'v45', u'v50', u'v53',\n",
      "       u'v57', u'v58', u'v62', u'v68', u'v69', u'v72', u'v80', u'v81', u'v82',\n",
      "       u'v85', u'v88', u'v90', u'v93', u'v98', u'v99', u'v100', u'v114',\n",
      "       u'v115', u'v119', u'v120', u'v123', u'v124', u'v127', u'v129',\n",
      "       u'v22_avg', u'v22_std', u'v24_avg', u'v24_std', u'v30_avg', u'v30_std',\n",
      "       u'v31_avg', u'v31_std', u'v47_avg', u'v47_std', u'v52_avg', u'v52_std',\n",
      "       u'v56_avg', u'v56_std', u'v66_avg', u'v66_std', u'v71_avg', u'v71_std',\n",
      "       u'v75_avg', u'v75_std', u'v79_avg', u'v79_std', u'v112_avg',\n",
      "       u'v112_std', u'v113_avg', u'v113_std', u'v125_avg', u'v125_std'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "train = pd.read_csv('/home/nick/01-projects/07-competitions/04-Paribas/data/train.csv')\n",
    "test = pd.read_csv('/home/nick/01-projects/07-competitions/04-Paribas/data/test.csv')\n",
    "gptrain, gptest = PrepareData(train, test)\n",
    "features = gptrain.columns[1:-1]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v4</th>\n",
       "      <th>v6</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v12</th>\n",
       "      <th>v14</th>\n",
       "      <th>v16</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>...</th>\n",
       "      <th>v75_std</th>\n",
       "      <th>v79_avg</th>\n",
       "      <th>v79_std</th>\n",
       "      <th>v112_avg</th>\n",
       "      <th>v112_std</th>\n",
       "      <th>v113_avg</th>\n",
       "      <th>v113_std</th>\n",
       "      <th>v125_avg</th>\n",
       "      <th>v125_std</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>6.085711</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.106720</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425520</td>\n",
       "      <td>0.758879</td>\n",
       "      <td>0.427772</td>\n",
       "      <td>0.774652</td>\n",
       "      <td>0.417869</td>\n",
       "      <td>0.823883</td>\n",
       "      <td>0.380924</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.417919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>6.507647</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425520</td>\n",
       "      <td>0.627499</td>\n",
       "      <td>0.483516</td>\n",
       "      <td>0.787425</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>0.685331</td>\n",
       "      <td>0.464398</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.406620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>6.384670</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.244541</td>\n",
       "      <td>0.144258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427877</td>\n",
       "      <td>0.758879</td>\n",
       "      <td>0.427772</td>\n",
       "      <td>0.769508</td>\n",
       "      <td>0.421401</td>\n",
       "      <td>0.823883</td>\n",
       "      <td>0.380924</td>\n",
       "      <td>0.769508</td>\n",
       "      <td>0.421401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>9.646653</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>5.517242</td>\n",
       "      <td>1.224114</td>\n",
       "      <td>0.231630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425520</td>\n",
       "      <td>0.892485</td>\n",
       "      <td>0.309773</td>\n",
       "      <td>0.748172</td>\n",
       "      <td>0.434117</td>\n",
       "      <td>0.823883</td>\n",
       "      <td>0.380924</td>\n",
       "      <td>0.733057</td>\n",
       "      <td>0.442516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>6.320087</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425520</td>\n",
       "      <td>0.689940</td>\n",
       "      <td>0.462525</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.421625</td>\n",
       "      <td>0.685331</td>\n",
       "      <td>0.464398</td>\n",
       "      <td>0.766771</td>\n",
       "      <td>0.423019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        v4        v6         v9       v10       v12        v14       v16  \\\n",
       "0   3  3.921026  2.599278   9.999999  0.503281  6.085711  11.636387  8.571429   \n",
       "1   4 -1.000000 -1.000000  -1.000000  1.312910  6.507647  11.636386 -1.000000   \n",
       "2   5  4.410969  3.979592  12.666667  0.765864  6.384670   9.603542  5.882353   \n",
       "3   6  4.225930  2.097700   8.965516  6.542669  9.646653  14.094723  5.517242   \n",
       "4   8 -1.000000 -1.000000  -1.000000  1.050328  6.320087  10.991098 -1.000000   \n",
       "\n",
       "        v18       v19   ...     v75_std   v79_avg   v79_std  v112_avg  \\\n",
       "0  0.106720  0.148883   ...    0.425520  0.758879  0.427772  0.774652   \n",
       "1 -1.000000 -1.000000   ...    0.425520  0.627499  0.483516  0.787425   \n",
       "2  0.244541  0.144258   ...    0.427877  0.758879  0.427772  0.769508   \n",
       "3  1.224114  0.231630   ...    0.425520  0.892485  0.309773  0.748172   \n",
       "4 -1.000000 -1.000000   ...    0.425520  0.689940  0.462525  0.768844   \n",
       "\n",
       "   v112_std  v113_avg  v113_std  v125_avg  v125_std  TARGET  \n",
       "0  0.417869  0.823883  0.380924  0.774775  0.417919       1  \n",
       "1  0.409172  0.685331  0.464398  0.791219  0.406620       1  \n",
       "2  0.421401  0.823883  0.380924  0.769508  0.421401       1  \n",
       "3  0.434117  0.823883  0.380924  0.733057  0.442516       1  \n",
       "4  0.421625  0.685331  0.464398  0.766771  0.423019       1  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = gptrain.drop([\"ID\",\"TARGET\"],axis=1)\n",
    "X_submission = gptest.drop([\"ID\"],axis=1)\n",
    "y = gptrain[\"TARGET\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # seed to shuffle the train set\n",
    "\n",
    "n_folds = 10\n",
    "verbose = True\n",
    "shuffle = False\n",
    "\n",
    "X, y, X_submission = load_data.load()\n",
    "\n",
    "if shuffle:\n",
    "    idx = np.random.permutation(y.size)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = list(StratifiedKFold(y, n_folds))\n",
    "\n",
    "clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "            GradientBoostingClassifier(learn_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)]\n",
    "\n",
    "print \"Creating train and test sets for blending.\"\n",
    "    \n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "    \n",
    "for j, clf in enumerate(clfs):\n",
    "    print j, clf\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print \"Fold\", i\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:,1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:,1]\n",
    "    dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "print\n",
    "print \"Blending.\"\n",
    "clf = LogisticRegression()\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:,1]\n",
    "\n",
    "print \"Linear stretch of predictions to [0,1]\"\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "\n",
    "print \"Saving Results.\"\n",
    "np.savetxt(fname='test.csv', X=y_submission, fmt='%0.9f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
