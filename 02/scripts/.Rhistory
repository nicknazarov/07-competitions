install.packages("pROC")
install.packages("e1071")
install.packages("caret")
install.packages("ggplot2")
install.packages("Matrix")
install.packages("xgboost")
rm(list=ls())
#setwd("/home/nazarov/07-competitions/02/scripts/")
setwd("/home/nick/01-projects/07-competitions/02/scripts/")
source("lib_func.R")
libraryBoot()
#PATH <- "/home/nazarov/07-competitions/02/data/"
#PATH_2 <- "/home/nazarov/Рабочий стол/santander.pdf"
PATH <- "/home/nick/01-projects/07-competitions/02/data/"
PATH_2 <- "/home/nick/Рабочий стол/santander.pdf"
N_CAT <- 15
FOR_SEED <- 1234
PCT <- 0.3
N_FACTORS <- 1:30
cat("Getting data\n")
print(system.time(x <- getData(PATH)))
cat("Transforming data\n")
print(system.time({
x <- xform_data(x, N_CAT)
}))
cat("Getting data\n")
print(system.time(x_raw <- getData(PATH)))
cat("Transforming data\n")
print(system.time({
x <- xform_data(x_raw, N_CAT)
}))
str(x$train, list.len =168 )
c(1,2,3,4,5)>3
as.integer(c(1,2,3,4,5)>3)
cat("Transforming data\n")
print(system.time({
x <- xform_data(x_raw, N_CAT)
}))
cat("Transforming data\n")
print(system.time({
x <- xform_data(x_raw, N_CAT)
}))
v38 <- as.data.frame(table(x_raw$train$var38))
v38 <- v38[order(v38[,2], decreasing = TRUE),]
as.numeric(levels(v38))[v38]
as.numeric(levels(v38))[1]
as.numeric(levels(v38))[v38[1,1]]
as.numeric(levels(v38[,1]))[v38[,1]]
as.numeric(levels(v38[,1]))[v38[,1]][1]
v38[,1] <-  as.numeric(levels(v38[,1]))[v38[,1]]
View(v38)
v38 <- as.data.frame(table(x_raw$train$var38))
v38 <- v38[order(v38[,2], decreasing = TRUE),]
View(v38)
v38[,1] <-  as.numeric(levels(v38[,1]))[v38[,1]]
View(v38)
cat("Transforming data\n")
print(system.time({
x <- xform_data(x_raw, N_CAT)
}))
source("lib_func.R")
cat("Transforming data\n")
print(system.time({
x <- xform_data(x_raw, N_CAT)
}))
str(x$train, list.len =168 )
cat("Feature selection data\n")
print(system.time(list_of_features <- imp_features_rf(x, FOR_SEED)))
top_N_features <- list_of_features[N_FACTORS,2]
cat("Plot features importance\n")
plot(list_of_features[,1])
cat("Print hist for top factors\n")
print_to_file_top_fact (PATH_2, x$train, top_N_features)
View(list_of_features)
save(list_of_features,file='output/factor_importance.rda')
save(list_of_features,file='factor_importance.rda')
tt <- read(file='factor_importance.rda')
tt <- load(file='factor_importance.rda')
tt
save(data=list_of_features,file='factor_importance.rda')
tt <- load(file='factor_importance.rda')
tt <- load(factor_importance.rda)
tt <- load('factor_importance.rda')
tt
save(list=list_of_features,file='factor_importance.rda')
tt <- load('factor_importance.rda')
save(list_of_features,file='factor_importance.rda')
tt <- load('factor_importance.rda')
tt <- load('factor_importance.RData')
rda
save(list_of_features,file='factor_importance.RData')
tt <- load('factor_importance.RData')
tt <- unlink('factor_importance.RData')
load('_importance.RData')
save(list_of_features,file='_importance.RData')
load('_importance.RData')
save(list_of_features,file='list_of_features.RData')
load('list_of_features.RData')
corr(x$train[,top_N_features])
cor(x$train[,top_N_features])
cor(as.integer(x$train[,top_N_features]))
cor(x_raw$train[,top_N_features])
top_N_features
cor(x_raw$train[,!(top_N_features %in% c("n0","flag_big_mort")])
cor(x_raw$train[,!(top_N_features %in% c("n0","flag_big_mort"))]
cor( x_raw$train[,!(top_N_features %in% c("n0","flag_big_mort")) ])
corr <- as.data.frame(cor( x_raw$train[,!(top_N_features %in% c("n0","flag_big_mort")) ]))
View(corr)
View(corr)
(top_N_features %in% c("n0","flag_big_mort"))
corr <- as.data.frame(cor( x_raw$train[,top_N_features[!(top_N_features %in% c("n0","flag_big_mort")) ]]))
View(corr)
install.packages("readr")
install.packages("curl")
library(stringr)
library(caret)
library(car)
set.seed(1234)
library(xgboost)
library(Matrix)
options(scipen=999)
train <- x$train
test <- x$test
# ---------------------------------------------------
# Features
feature.names <- names(train)
feature.names <- feature.names[-grep('^ID$', feature.names)]
feature.names <- feature.names[-grep('^TARGET$', feature.names)]
feature.formula <- formula(paste('TARGET ~ ', paste(feature.names, collapse = ' + '), sep = ''))
# ---------------------------------------------------
# Matrix
indexes <- sample(seq_len(nrow(train)), floor(nrow(train)*0.85))
data <- sparse.model.matrix(feature.formula, data = train[indexes, ])
sparseMatrixColNamesTrain <- colnames(data)
dtrain <- xgb.DMatrix(data, label = train[indexes, 'TARGET'])
rm(data)
dvalid <- xgb.DMatrix(sparse.model.matrix(feature.formula, data = train[-indexes, ]),
label = train[-indexes, 'TARGET'])
dtest <- sparse.model.matrix(feature.formula, data = test)
watchlist <- list(valid = dvalid, train = dtrain)
# ---------------------------------------------------
# XGBOOST
params <- list(booster = "gbtree", objective = "binary:logistic",
max_depth = 8, eta = 0.05,
colsample_bytree = 0.65, subsample = 0.95)
model <- xgb.train(params = params, data = dtrain,
nrounds = 500, early.stop.round = 50,
eval_metric = 'auc', maximize = T,
watchlist = watchlist, print.every.n = 10)
pred <- predict(model, dtest)
# ---------------------------------------------------
# SAVE
submission <- data.frame(ID = test$ID, TARGET = pred)
write.csv(submission, 'imp_xgboost_first_simple.csv', row.names=FALSE, quote = FALSE)
# Compute feature importance matrix
importance_matrix <- xgb.importance(names, model = xgb)
# Nice graph
xgb.plot.importance(importance_matrix[1:10,])
str(dtrain)
dvalid <- xgb.DMatrix(sparse.model.matrix(feature.formula, data = train[-indexes, ]),
label = train[-indexes, c('TARGET')])
test$TARGET <- -1
dtrain <- xgb.DMatrix(data, label = train[indexes, 'TARGET'])
rm(data)
dvalid <- xgb.DMatrix(sparse.model.matrix(feature.formula, data = train[-indexes, ]),
label = train[-indexes, c('TARGET')])
dtest <- sparse.model.matrix(feature.formula, data = test)
watchlist <- list(valid = dvalid, train = dtrain)
# ---------------------------------------------------
# XGBOOST
params <- list(booster = "gbtree", objective = "binary:logistic",
max_depth = 8, eta = 0.05,
colsample_bytree = 0.65, subsample = 0.95)
model <- xgb.train(params = params, data = dtrain,
nrounds = 500, early.stop.round = 50,
eval_metric = 'auc', maximize = T,
watchlist = watchlist, print.every.n = 10)
pred <- predict(model, dtest)
# ---------------------------------------------------
# SAVE
submission <- data.frame(ID = test$ID, TARGET = pred)
write.csv(submission, 'imp_xgboost_first_simple.csv', row.names=FALSE, quote = FALSE)
# Compute feature importance matrix
importance_matrix <- xgb.importance(names, model = xgb)
# Nice graph
xgb.plot.importance(importance_matrix[1:10,])
str( train$TARGET )
str( as.integer(as.character(train$TARGET)) )
train <- x$train
test <- x$test
#str(dtrain)
train$TARGET <- as.integer(as.character(train$TARGET))
test$TARGET <- -1
# ---------------------------------------------------
# Features
feature.names <- names(train)
feature.names <- feature.names[-grep('^ID$', feature.names)]
feature.names <- feature.names[-grep('^TARGET$', feature.names)]
feature.formula <- formula(paste('TARGET ~ ', paste(feature.names, collapse = ' + '), sep = ''))
# ---------------------------------------------------
# Matrix
indexes <- sample(seq_len(nrow(train)), floor(nrow(train)*0.85))
data <- sparse.model.matrix(feature.formula, data = train[indexes, ])
sparseMatrixColNamesTrain <- colnames(data)
dtrain <- xgb.DMatrix(data, label = train[indexes, 'TARGET'])
rm(data)
dvalid <- xgb.DMatrix(sparse.model.matrix(feature.formula, data = train[-indexes, ]),
label = train[-indexes, c('TARGET')])
dtest <- sparse.model.matrix(feature.formula, data = test)
watchlist <- list(valid = dvalid, train = dtrain)
# ---------------------------------------------------
# XGBOOST
params <- list(booster = "gbtree", objective = "binary:logistic",
max_depth = 8, eta = 0.05,
colsample_bytree = 0.65, subsample = 0.95)
model <- xgb.train(params = params, data = dtrain,
nrounds = 500, early.stop.round = 50,
eval_metric = 'auc', maximize = T,
watchlist = watchlist, print.every.n = 10)
pred <- predict(model, dtest)
# ---------------------------------------------------
# SAVE
submission <- data.frame(ID = test$ID, TARGET = pred)
write.csv(submission, 'imp_xgboost_first_simple.csv', row.names=FALSE, quote = FALSE)
# Compute feature importance matrix
importance_matrix <- xgb.importance(names, model = xgb)
# Nice graph
xgb.plot.importance(importance_matrix[1:10,])
importance_matrix <- xgb.importance(feature.names, model = model)
xgb.plot.importance(importance_matrix[1:10,])
install.packages("Ckmeans.1d.dp")
install.packages("Ckmeans.1d.dp")
print(importance_matrix[1:10,])
print(importance_matrix[1:30,])
save(importance_matrix ,"importance_xgboost.RDA")
save(importance_matrix ,file="importance_xgboost.RDA")
